{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55031425-b11d-471b-a6e5-7bcb16c4eae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/anuj/anaconda3/lib/python3.12/site-packages (0.3.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.21)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (0.1.145)\n",
      "Requirement already satisfied: numpy<2,>=1.26.2 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/anuj/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/anuj/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anuj/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/anuj/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/anuj/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anuj/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anuj/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anuj/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anuj/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/anuj/anaconda3/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: anyio in /home/anuj/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/anuj/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /home/anuj/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/anuj/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/anuj/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d4fa1f-30ff-42f3-8d4c-4dbb9390262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7169/2690369194.py:8: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n",
      "/tmp/ipykernel_7169/2690369194.py:14: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(\"Explain LangChain like I’m 5.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain LangChain like I’m 5.\n",
      "\n",
      "LangChain is like a magic tool that helps people talk to each other in different languages. It's like having a big toy robot that can understand and speak many languages, so you can play with friends from all over the world!\n",
      "\n",
      "What is LangChain used for?\n",
      "\n",
      "LangChain is a helpful tool used for translating text, documents, and even conversations between different languages. It can be used in many different settings, such as in business meetings, tourist destinations,\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",  # Or deepseek\n",
    "    huggingfacehub_api_token=token,\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_new_tokens\": 100}\n",
    ")\n",
    "\n",
    "response = llm(\"Explain LangChain like I’m 5.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b2c508-a863-47b8-bd58-7ac887697f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"Indian Casual Tone\n",
    "\"\"\"\n",
    "\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{customer}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c15ed7b-a575-4c33-8894-219fdf0d75ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer', 'style']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "print(prompt_template.messages[0].prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03186442-fd7c-45ce-a563-7706ed2c2668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is Indian Casual Tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "customer_message = prompt_template.format_messages(customer=customer,style=style)\n",
    "print(customer_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96b233f-8430-4ebb-8215-c4d703fb3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is Indian Casual Tone\n",
      ". text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n",
      "Translate the text that is delimited by triple backticks into a style that is Indian Casual Tone\n",
      ". text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n",
      ". text: Oh my, I am really angry because my blender lid flew off and splattered my kitchen walls with smoothie! And to add to my problems, the warranty does not cover the cost of cleaning up my kitchen. I really need your help right now, buddy!\n",
      "\n",
      "Note: The text has been translated into a more casual and informal tone that is commonly used in India. I have also replaced some of the pirate slang with more common colloquial\n"
     ]
    }
   ],
   "source": [
    "response_text = llm(customer_message[0].content)\n",
    "print(customer_message[0].content)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7723ad7-0efd-457d-9b0f-7ea50d3a3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" A scored 5432 in 100 matches\\n\n",
    "B scored 345 runs in 8 matches\\n\n",
    "C scored 7890 runs in 89 matches\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e37fd49c-0520-49bb-9920-b447ebaf90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Increase 100 runs to all the person mentioned in triple backticks\\\n",
    "            text:```{text}```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e75421-e3cc-4393-8216-b3daabc695bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['customer', 'style'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['customer', 'style'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{customer}```\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt_temp = ChatPromptTemplate.from_template(template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09ffc771-e3aa-4f4a-aaf9-9dbe49240a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=' Increase 100 runs to all the person mentioned in triple backticks            text:``` A scored 5432 in 100 matches\\n\\nB scored 345 runs in 8 matches\\n\\nC scored 7890 runs in 89 matches\\n```', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "prompt_message = prompt_temp.format_messages(text=text)\n",
    "print(prompt_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1528b0d6-3bdf-4951-a7fb-572282607f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Increase 100 runs to all the person mentioned in triple backticks            text:``` A scored 5432 in 100 matches\n",
      "\n",
      "B scored 345 runs in 8 matches\n",
      "\n",
      "C scored 7890 runs in 89 matches\n",
      "```\n",
      "To increase the runs of each player by 100, you can create a new text by looping through the lines and modifying the runs accordingly. Here's a Python solution:\n",
      "\n",
      "```python\n",
      "lines = text.split('\\n')\n",
      "for i, line in enumerate(lines):\n",
      "    if line:  # skip empty lines\n",
      "        parts = line.split(' ')\n",
      "        runs = int(parts[-2]) + 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_answer = llm(prompt_message[0].content)\n",
    "print(response_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4536beee-4137-4381-97a3-73f69a392c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template = \"\"\" For each of the following text format it like this\n",
    "                      name : who scored the runs \n",
    "                      runs : how much he/she scored totally\n",
    "                      matches : number of matches he/she played\n",
    "\n",
    "                Format it into JSON format like this\n",
    "                name,\n",
    "                runs,\n",
    "                matches\n",
    "\n",
    "                text : {text}\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3b26193-69c2-4b33-bce4-8df7cbf22f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template=' For each of the following text format it like this\\n                      name : who scored the runs \\n                      runs : how much he/she scored totally\\n                      matches : number of matches he/she played\\n\\n                Format it into JSON format like this\\n                name,\\n                runs,\\n                matches\\n\\n                text : {text}\\n                '), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5ef96fe-6d72-4c3b-a18a-76dd3f759341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=' For each of the following text format it like this\\n                      name : who scored the runs \\n                      runs : how much he/she scored totally\\n                      matches : number of matches he/she played\\n\\n                Format it into JSON format like this\\n                name,\\n                runs,\\n                matches\\n\\n                text :  A scored 5432 in 100 matches\\n\\nB scored 345 runs in 8 matches\\n\\nC scored 7890 runs in 89 matches\\n\\n                ', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "message = prompt_template.format_messages(text=text)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec8013ca-d200-4e9b-8746-7fa5ffb2eadd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For each of the following text format it like this\n",
      "                      name : who scored the runs \n",
      "                      runs : how much he/she scored totally\n",
      "                      matches : number of matches he/she played\n",
      "\n",
      "                Format it into JSON format like this\n",
      "                name,\n",
      "                runs,\n",
      "                matches\n",
      "\n",
      "                text :  A scored 5432 in 100 matches\n",
      "\n",
      "B scored 345 runs in 8 matches\n",
      "\n",
      "C scored 7890 runs in 89 matches\n",
      "\n",
      "                   [\n",
      "                       {\n",
      "                           \"name\" : \"A\",\n",
      "                           \"runs\" : 5432,\n",
      "                           \"matches\" : 100\n",
      "                       },\n",
      "                       {\n",
      "                           \"name\" : \"B\",\n",
      "                           \"runs\" : 345,\n",
      "                           \"matches\" : 8\n",
      "                       },\n",
      "                       {\n",
      "                           \"name\" : \"C\",\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = llm(message[0].content)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ee1cf8e-e115-404c-8481-d8e0b5fb2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser \n",
    "from langchain.output_parsers import ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87bc6bf8-260d-4b91-9843-2a33ba890d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_schema = ResponseSchema(\n",
    "    name = \"name\",\n",
    "    description = \"who scored the runs ?\"\n",
    ")\n",
    "\n",
    "runs_schema = ResponseSchema(\n",
    "    name=\"runs\",\n",
    "    description = \"how much he/she scored totally\"\n",
    ")\n",
    "\n",
    "matches_schema = ResponseSchema(\n",
    "    name=\"matches\",\n",
    "    description = \"number of matches he/she played\"\n",
    ")\n",
    "\n",
    "response_schemas = [name_schema,runs_schema,matches_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbec60cf-5dea-4113-aba2-04d1ba00abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // who scored the runs ?\n",
      "\t\"runs\": string  // how much he/she scored totally\n",
      "\t\"matches\": string  // number of matches he/she played\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f45c5ce-eb4f-47b1-a976-4dfc10989426",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_template = \"\"\"For each of the following text extract the information\n",
    "                      name : who scored the runs \n",
    "                      runs : how much he/she scored totally\n",
    "                      matches : number of matches he/she played\n",
    "\n",
    "                Format it into JSON format like this\n",
    "                name,\n",
    "                runs,\n",
    "                matches\n",
    "\n",
    "                text : {text}\n",
    "                format_instructions:{format_instructions}\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ad41391-5ec4-4ab8-bb1d-e8617b8d54a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='For each of the following text extract the information\\n                      name : who scored the runs \\n                      runs : how much he/she scored totally\\n                      matches : number of matches he/she played\\n\\n                Format it into JSON format like this\\n                name,\\n                runs,\\n                matches\\n\\n                text :  A scored 5432 in 100 matches\\n\\nB scored 345 runs in 8 matches\\n\\nC scored 7890 runs in 89 matches\\n\\n                format_instructions:The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"name\": string  // who scored the runs ?\\n\\t\"runs\": string  // how much he/she scored totally\\n\\t\"matches\": string  // number of matches he/she played\\n}\\n```\\n                ', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(final_template)\n",
    "prompt = prompt_template.format_messages(text=text,format_instructions=format_instructions)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "588a2322-7af9-4a8b-b1ca-b6e793999557",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument `prompt` is expected to be a string. Instead found <class 'list'>. If you want to run the LLM on multiple prompts, use `generate` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response_val \u001b[38;5;241m=\u001b[39m llm(prompt)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_val)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1275\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1270\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1274\u001b[0m     )\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m   1278\u001b[0m         [prompt],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m   1287\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Argument `prompt` is expected to be a string. Instead found <class 'list'>. If you want to run the LLM on multiple prompts, use `generate` instead."
     ]
    }
   ],
   "source": [
    "response_val = llm(prompt)\n",
    "print(response_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63ef404a-3c9e-447c-8e3d-cbe17b3c9421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each of the following text extract the information\n",
      "                      name : who scored the runs \n",
      "                      runs : how much he/she scored totally\n",
      "                      matches : number of matches he/she played\n",
      "\n",
      "                Format it into JSON format like this\n",
      "                name,\n",
      "                runs,\n",
      "                matches\n",
      "\n",
      "                text :  A scored 5432 in 100 matches\n",
      "\n",
      "B scored 345 runs in 8 matches\n",
      "\n",
      "C scored 7890 runs in 89 matches\n",
      "\n",
      "                format_instructions:The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // who scored the runs ?\n",
      "\t\"runs\": string  // how much he/she scored totally\n",
      "\t\"matches\": string  // number of matches he/she played\n",
      "}\n",
      "```\n",
      "                      formatted_output:\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": \"A\",\n",
      "\t\"runs\": \"5432\",\n",
      "\t\"matches\": \"100\"\n",
      "}\n",
      "\n",
      "{\n",
      "\t\"name\": \"B\",\n",
      "\t\"runs\": \"345\",\n",
      "\t\"matches\": \"8\"\n",
      "}\n",
      "\n",
      "{\n",
      "\t\"name\": \"C\",\n",
      "\t\"runs\": \"7890\",\n"
     ]
    }
   ],
   "source": [
    "print(response_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59c28685-0a56-4512-ae2b-95f2dc953754",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_dict \u001b[38;5;241m=\u001b[39m output_parser\u001b[38;5;241m.\u001b[39mparse(response_val\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response_val.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150a2fa-8525-40f1-8610-294820287f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
